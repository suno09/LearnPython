{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJMS8p3wfPXO"
   },
   "source": [
    "## Stage 1: Installing dependencies and notebook gpu setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRHFdNYAfWKJ"
   },
   "source": [
    "## Stage 2: Importing dependencies for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tS5xFeQwe9Xu",
    "outputId": "9aacd236-4553-4a05-999d-aca4b83913b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8zYubaPfy-S"
   },
   "source": [
    "## Stage 3: Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOAGjiPogF0w"
   },
   "source": [
    "### Loading the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v1N6LbS-e9a1"
   },
   "outputs": [],
   "source": [
    "#Setting class names for the dataset\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "f13-8-m_fqKP",
    "outputId": "f782a5f1-7778-4138-c647-877b2d48e878"
   },
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqDIpsJWgUkz"
   },
   "source": [
    "### Image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-QFncPlpgNmU"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L1rFHX67gc6G",
    "outputId": "5342e459-6431-4e70-c7c9-6dd332bb650c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ve2WbRGWgc3I"
   },
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "7jwvNZ82gh9d",
    "outputId": "db6d0be2-de1f-4c2b-8b8d-c4aaba462b62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23f94617d90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXiuZulIguyf"
   },
   "source": [
    "## Stage 4: Building a Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFTetk8ngy0f"
   },
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1TR0JGP5gq2i"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j92d4FE0hTZV"
   },
   "source": [
    "### Adding the first CNN Layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "- filters: 32\n",
    "- kernel_size:3\n",
    "- padding: same\n",
    "- activation: relu\n",
    "- input_shape: (32, 32, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LSkL1iOvg_dE"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfRAaRmWiSlZ"
   },
   "source": [
    "### Adding the second CNN Layer and max pool layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "- filters: 32\n",
    "- kernel_size:3\n",
    "- padding: same\n",
    "- activation: relu\n",
    "\n",
    "MaxPool layer hyper-parameters:\n",
    "- pool_size: 2\n",
    "- strides: 2\n",
    "- padding: valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sSl7Es5yidMp"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wmP9h5wliAR6"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd8ERDyvin-0"
   },
   "source": [
    "### Adding the third CNN Layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "\n",
    "    filters: 64\n",
    "    kernel_size:3\n",
    "    padding: same\n",
    "    activation: relu\n",
    "    input_shape: (32, 32, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "i9HWy6aFixEw"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O55kyOQGi44V"
   },
   "source": [
    "###  Adding the fourth CNN Layer and max pool layer\n",
    "\n",
    "CNN layer hyper-parameters:\n",
    "\n",
    "    filters: 64\n",
    "    kernel_size:3\n",
    "    padding: same\n",
    "    activation: relu\n",
    "\n",
    "MaxPool layer hyper-parameters:\n",
    "\n",
    "    pool_size: 2\n",
    "    strides: 2\n",
    "    padding: valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5b7vAuhjjCF2"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oc493G2BjFhg"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hGnR3aXjKbZ"
   },
   "source": [
    "### Adding the Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QLzu2cCVjI5Z"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpeRUvVWjR1W"
   },
   "source": [
    "### Adding the first Dense layer\n",
    "\n",
    "Dense layer hyper-parameters:\n",
    "- units/neurons: 128\n",
    "- activation: relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FWzYY8kKjhnZ"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaakKTqRjrkF"
   },
   "source": [
    "### Adding the second Dense layer (output layer)\n",
    "\n",
    "Dense layer hyper-parameters:\n",
    "\n",
    " - units/neurons: 10 (number of classes)\n",
    " - activation: softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4t-JmzRvjnBj"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "aRr3bCU-ti06",
    "outputId": "8c18a1c8-5607-4b12-c549-787e721e4a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,274\n",
      "Trainable params: 591,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYgvbNihtprw"
   },
   "source": [
    "### Compiling the model\n",
    "\n",
    "#### sparse_categorical_accuracy\n",
    "sparse_categorical_accuracy checks to see if the maximal true value is equal to the index of the maximal predicted value.\n",
    "\n",
    "https://stackoverflow.com/questions/44477489/keras-difference-between-categorical-accuracy-and-sparse-categorical-accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oYHELxz4tsa-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gox3SmwUtwgX"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "D3MHvRYKe9fN",
    "outputId": "39dbc848-9a88-4663-a09b-f7469a25b9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 1.3733 - sparse_categorical_accuracy: 0.5032\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.9221 - sparse_categorical_accuracy: 0.6766\n",
      "Epoch 3/5\n",
      " 332/1563 [=====>........................] - ETA: 1:50 - loss: 0.7571 - sparse_categorical_accuracy: 0.7327- ETA"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LAHEG~1.CHE\\AppData\\Local\\Temp/ipykernel_21392/249500259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonprojects\\learnpython\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8C7Pm0NuOrJ"
   },
   "source": [
    "### Model evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Z9r8TtNet3D0",
    "outputId": "c09abc05-5b1b-4208-f654-09c24c9914d8"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0rpAPpfzuV0p",
    "outputId": "99643f7f-23ce-4ab8-c4e0-798f00e81c3d"
   },
   "outputs": [],
   "source": [
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSKfLqi5urEh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Building a Convolutional Neural Network in TensorFlow 2.0 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
